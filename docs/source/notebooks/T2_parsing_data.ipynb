{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2. Parsing a data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python libraries used in this section other than PyXC\n",
    "- Pandas (`pandas`)\n",
    "- Numpy  (`numpy`)\n",
    "- Scikit Image (`scikit-image`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a data\n",
    "This is intended for the basic course if you are not familiar with Python. If you can read your own data into a NumPy array or Python iterables, you can skip this tutorial.\n",
    "\n",
    "One best case to read data is finding a library which is able to handle the format you want to read in. For example, the `hyperspy` module is able to read `.spd` files to build an integrated window map. Utilizing pre-written libraries drastically reduces the time for the correlation. If desired file readers are not available, it will be required to build a code snippet for that purpose.\n",
    "\n",
    "This section explains about *how to read scientific data if appropriate readers are not available*. In most cases it is not an issue.\n",
    "\n",
    "## Rule of Thumb\n",
    "1. Find the library that can read your data.\n",
    "2. Export your data to easily readable formats.\n",
    "3. Try to implement the reader if that is absolutely necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common practice to reading data\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Info:** This section is prepared to demonstrate how to read scientific data. This section itself is not mandatorily required to proceed with a correlation task. However, often scientific data requires own parsers to read it. In that case, this section might help you.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV-like formats\n",
    "The most common formats that are available in scientific data are csv-like data formulations. Those data consist of a header and a data part. After the header part, a continuous stream of column-separated data separated by respective delimiters is followed. Delimiters are often one or more tab (`\\t`), space (` `), comma (`,`), or semicolon (`:`) but not limited to one of them.\n",
    "\n",
    "One example of CSV-like format is a `.ctf` file which is commonly used for representing EBSD scanning results:\n",
    "```\n",
    "Channel Text File\n",
    "Prj unnamed\n",
    "Author\t[Unknown]\n",
    "JobMode\tGrid\n",
    "XCells\t100\n",
    "YCells\t75\n",
    "XStep\t0.277648546987832\n",
    "YStep\t0.277648546987833\n",
    "AcqE1\t0\n",
    "AcqE2\t0\n",
    "AcqE3\t0\n",
    "Euler angles refer to Sample Coordinate system (CS0)!\tMag\t4500\tCoverage\t100\tDevice\t0\tKV\t20\tTiltAngle\t70\tTiltAxis\t0\n",
    "Phases\t2\n",
    "4.235;4.235;4.235\t90;90;90\tOsbornite\t11\t225\n",
    "3.516;3.516;3.516\t90;90;90\tNickel\t11\t225\n",
    "Phase\tX\tY\tBands\tError\tEuler1\tEuler2\tEuler3\tMAD\tBC\tBS\n",
    "2\t0.0000\t0.0000\t11\t0\t160.45\t47.733\t233.82\t1.0211\t160\t255\n",
    "2\t0.2776\t0.0000\t10\t0\t160.15\t47.888\t233.74\t1.3246\t161\t255\n",
    "2\t0.5553\t0.0000\t10\t0\t160.14\t47.928\t234.00\t1.3319\t161\t255\n",
    "2\t0.8329\t0.0000\t10\t0\t159.83\t47.686\t234.36\t1.1272\t157\t255\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `csv` module to load your data. However, this might not the best option since header information is tricky to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = list()\n",
    "with open(\"./data/SiC_in_NiSA.ctf\", mode=\"r\") as f:\n",
    "    tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for _ in range(15):\n",
    "        next(tsv_reader)\n",
    "\n",
    "    for row in tsv_reader:\n",
    "        data.append(row)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple options to do this more conveniently. You can use Pandas or NumPy. The library `Pandas` is a convenient option since it awares column structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ebsd_pd = pd.read_csv(\n",
    "    \"./data/SiC_in_NiSA.ctf\", skiprows=15, delim_whitespace=True, header=[0]\n",
    ")\n",
    "ebsd_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ignore the first 7 lines specifying `skiprows` was required and to ignore multiple spaces specifying the `delim_whitespace` keyword was needed. Since there is no header, the `header` keyword is set to `None`.\n",
    "\n",
    "NumPy can also aware columns in CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ebsd_np = np.genfromtxt(\n",
    "    \"./data/SiC_in_NiSA.ctf\", dtype=float, skip_header=15, delimiter=\"\\t\", names=True\n",
    ")\n",
    "ebsd_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Data Format\n",
    "Interpreting binary data can be quite complex. Despite its intricacy and unavailability for plain reading, binary format is frequently used for storing datasets from various devices.\n",
    "\n",
    "Ideally, to read binary data, one should have a file specification. File formats such as `.ipr` or `.spd` are commonly available and hence implementing these isn't overly difficult (also, there is a nice library called `hyperspy`.)\n",
    "\n",
    "A preliminary strategy you might consider is identifying a method to convert the data into formats that are more readily accessible, such as CSV, TIFF, or TXT using your software in disposal. If this conversion isn't feasible, or you have a specific requirement to use binary format, you should look for a specialized reader on platforms like GitHub. There might be a library available that can handle this task.\n",
    "\n",
    "In the event that you're unable to find a solution and it becomes necessary to develop your own code, look for a file specification in the software's installation directory. Sometimes, the specifications for files are located within these directories. If all else fails and you're urgently in need of accessing specific data, consider requesting the binary format specifications from the device's manufacturer.\n",
    "\n",
    "Once you've acquired the file specification, you can use Python's standard library `struct` to retrieve the desired data from the binary file.\n",
    "\n",
    "However, if you can't access file specifications, you might have to resort to reverse engineering, which can be a painstaking process. I wish you good luck if this is your situation. Always remember to compare your reverse-engineered results with the software provided by the manufacturer to ensure accuracy.\n",
    "\n",
    "The code example provided below demonstrates how to read an eZAF quantified `.dat` file from EDAX TEAM Software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "\n",
    "class ED_ZAF_MAP:\n",
    "    def __init__(self, path):\n",
    "        self.metadata: dict = dict()\n",
    "        filename, extension = os.path.splitext(path)\n",
    "        self.map = self.data_reader(filename + \".dat\")\n",
    "\n",
    "    def data_reader(self, filename):\n",
    "        map_data = open(filename, \"rb\")\n",
    "        pixel_x = struct.unpack(\"i\", map_data.read(4))[0]\n",
    "        pixel_y = struct.unpack(\"i\", map_data.read(4))[0]\n",
    "        _ = struct.unpack(\"i\", map_data.read(4))[0]\n",
    "        _ = struct.unpack(\"i\", map_data.read(4))[0]\n",
    "        self.metadata.update(dict(pixel_x=pixel_x, pixel_y=pixel_y))\n",
    "\n",
    "        imdata = list()\n",
    "        for _ in range(pixel_x * pixel_y):\n",
    "            imdata.append(struct.unpack(\"d\", map_data.read(8))[0])\n",
    "        del map_data\n",
    "        return np.array(imdata).reshape(pixel_y, pixel_x)\n",
    "\n",
    "\n",
    "Ni = ED_ZAF_MAP(\"./data/map20221215113824374_ZafAt_Ni K.dat\")\n",
    "Ni.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(Ni.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Format\n",
    "Images serve as an important mode of representing scientific data, encompassing elements like metallographic micrographs, scanning electron microscope (SEM) images, and optical microscope imagery. Thankfully, Python offers a wide range of libraries that efficiently facilitate image reading. Specifically, in the original publications of this tool, a light micrograph panorama image was used to align results from electron back-scattered diffraction analysis and high-speed nano-indentation evaluations.\n",
    "\n",
    "Most image formats can be handled by the `cv2` or `scikit-image` libraries.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Info\n",
    "\n",
    "If you require a panorama image, the open-source, cross-platform image software `Huginn` is highly capable. A series of useful guides on this topic can be located via the links ''XXX''here and here'''XXX'''.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "limi_sk = skimage.io.imread(\"./data/example_image.jpg\")\n",
    "plt.imshow(limi_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use PIL also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "limi_pil = Image.open(\"./data/example_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using strategies that we've visited above, you should be able to read most of scientific data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
